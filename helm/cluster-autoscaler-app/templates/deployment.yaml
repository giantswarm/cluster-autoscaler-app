apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.name }}
  namespace: {{ .Values.namespace }}
  labels:
    {{- include "labels.common" . | nindent 4 }}
spec:
  replicas: 1
  selector:
    matchLabels:
      {{- include "labels.selector" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "labels.common" . | nindent 8 }}
    spec:
      serviceAccountName: {{ .Values.name }}
      securityContext:
        runAsUser: {{ .Values.userID }}
        runAsGroup: {{ .Values.groupID }}
      tolerations:
      - effect: NoSchedule
        operator: "Exists"
        key: node-role.kubernetes.io/master
      nodeSelector:
        kubernetes.io/role: master
      priorityClassName: giantswarm-critical
      containers:
        - image: "{{ .Values.image.registry }}/{{ .Values.image.name }}:{{ .Values.image.tag }}"
          name: {{ .Values.name }}
          resources:
            limits:
              memory: 400Mi
            requests:
              cpu: 100m
              memory: 400Mi
          command:
            - ./cluster-autoscaler
            - --v=4
            - --cloud-provider={{ .Values.provider }}
            - --expander={{ .Values.configmap.expander }}
            - --logtostderr=true
            # Don't use auto discovery in integration tests.
            {{- if eq .Values.e2e false }}
            {{- if .Values.Installation }}
            {{- if eq .Values.Istallation.V1.Provider.Kind "aws" }}
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/{{ .Values.Installation.V1.Name }}
            {{- else if eq .Values.Installation.V1.Provider.Kind "azure" }}
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/{{ .Values.clusterID }}
            {{- end }}
            {{- else }}
            {{- if eq .Values.provider "aws" }}
            - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/{{ .Values.clusterID }}
            # Turning runtime instance info acquisition off because of
            # https://github.com/kubernetes/autoscaler/issues/3076
            - --aws-use-static-instance-list=true
            {{- else if eq .Values.provider "azure" }}
            - --node-group-auto-discovery=label:cluster-autoscaler-enabled=true,cluster-autoscaler-name={{ .Values.clusterID }}
            {{- end }}
            {{- end }}
            {{- end }}
            - --skip-nodes-with-local-storage={{ .Values.configmap.skipNodesWithLocalStorage }}
            - --skip-nodes-with-system-pods={{ .Values.configmap.skipNodesWithSystemPods }}
            - --scale-down-unneeded-time={{ .Values.configmap.scaleDownUnneededTime }}
            - --scale-down-utilization-threshold={{ .Values.configmap.scaleDownUtilizationThreshold }}
            - --scan-interval={{ .Values.configmap.scanInterval }}
            - --stderrthreshold=info
          env:
          {{- if .Values.Installation }}
          # add configuration after availability sets migration to scale sets done  
          {{- else }}
          {{- if eq .Values.provider "azure" }}
            {{- if ne .Values.azure.subscriptionID "" }}
            - name: ARM_SUBSCRIPTION_ID
              value: {{ .Values.azure.subscriptionID }}
            {{- end }}
            - name: ARM_RESOURCE_GROUP
              value: {{ .Values.clusterID }}
            - name: ARM_USE_MANAGED_IDENTITY_EXTENSION
              value: {{ quote .Values.azure.managedIdentity }}
            - name: ARM_VM_TYPE
              value: {{ .Values.azure.vmType }}
          {{- end }}
          {{- end }}
          volumeMounts:
            - name: ssl-certs
              mountPath: /etc/ssl/certs/ca-certificates.crt
              readOnly: true
          imagePullPolicy: "Always"
      volumes:
        - name: ssl-certs
          hostPath:
            path: "/etc/ssl/certs/ca-certificates.crt"
